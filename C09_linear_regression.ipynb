{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-13T15:59:18.744889Z",
     "start_time": "2026-01-13T15:59:15.714906Z"
    }
   },
   "source": [
    "# 房价预测问题演示线性回归问题\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf\n",
    "\n",
    "# 加载房价数据集数据\n",
    "california = fetch_california_housing()\n",
    "print(california.data, california.data.shape)\n",
    "print(california.target)\n",
    "print(california.feature_names)\n",
    "\n",
    "x_train = california.data  # 特征值\n",
    "y_train = california.target  # 目标值 房价"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]] (20640, 8)\n",
      "[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:04:11.595025Z",
     "start_time": "2026-01-13T16:04:11.469744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 构建多成神经网络回归模型\n",
    "from keras import Input, layers\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(x_train.shape[1],)),  # 输入维度是8 因为特征就是8个\n",
    "    layers.Dense(units=64, activation='relu'),  # 隐藏层1\n",
    "    layers.Dense(units=32, activation='relu'),  # 隐藏层2\n",
    "    layers.Dense(units=16, activation='relu'),  # 隐藏层3\n",
    "    layers.Dense(units=1)  # 输出层 线性激活 预测房价是一个标量\n",
    "])\n",
    "model.summary()\n",
    "# x_train.shape[1] 开始是8，所以初始的输入维度是8\n",
    "# 每一层参数个数等于 输入维度*输出维度+偏置个数(输出维度)\n",
    "# 第一层参数个数 8*64+64=576\n",
    "# 第二层参数个数 64*32+32=2080  第一层输出维度也就是第二层输入维度是64"
   ],
   "id": "b3d9ca1babe2fe24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3201 (12.50 KB)\n",
      "Trainable params: 3201 (12.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:06:21.851099Z",
     "start_time": "2026-01-13T16:06:21.831155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 编译配置模型\n",
    "model.compile(\n",
    "    optimizer=\"adam\",loss=\"mse\",metrics=[\"mse\"] # 指定优化器 损失函数 评估指标\n",
    ")"
   ],
   "id": "6920135abcc5f131",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:10:20.492666Z",
     "start_time": "2026-01-13T16:09:59.716200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练模型\n",
    "#model.fit(x_train, y_train, epochs=50, batch_size=32,validation_split=0.2,verbose=1)  # 训练模型 分批次训练 20%验证集 显示进度条\n",
    "history = model.fit(x_train, # 输入数据（特征）\n",
    "y_train, # 目标数据（标签）\n",
    "epochs=100, # 训练轮数\n",
    "batch_size=32, # 每个训练批次的样本数量\n",
    "validation_split=0.2, # 从训练数据中划分验证集的比例\n",
    "verbose=1 # 日志显示模式（0=不显示，1=进度条，2=简洁显示）\n",
    ")\n",
    "print(f\"最终MSE: {history.history['mse'][-1]:.4f}\")"
   ],
   "id": "2ac8b8097a725ab2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 0s 533us/step - loss: 413.7871 - mse: 413.7871 - val_loss: 1.3411 - val_mse: 1.3411\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 0s 411us/step - loss: 1.1552 - mse: 1.1552 - val_loss: 1.0922 - val_mse: 1.0922\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 0s 432us/step - loss: 0.9822 - mse: 0.9822 - val_loss: 0.9195 - val_mse: 0.9195\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 0s 415us/step - loss: 1.0668 - mse: 1.0668 - val_loss: 0.8874 - val_mse: 0.8874\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 0s 390us/step - loss: 0.9290 - mse: 0.9290 - val_loss: 0.8456 - val_mse: 0.8456\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 0s 390us/step - loss: 1.8492 - mse: 1.8492 - val_loss: 0.7482 - val_mse: 0.7482\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 0s 466us/step - loss: 1.2373 - mse: 1.2373 - val_loss: 0.8808 - val_mse: 0.8808\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 0s 443us/step - loss: 16.4379 - mse: 16.4379 - val_loss: 1.1696 - val_mse: 1.1696\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 0s 402us/step - loss: 2.2505 - mse: 2.2505 - val_loss: 0.7242 - val_mse: 0.7242\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 0s 404us/step - loss: 1.2037 - mse: 1.2037 - val_loss: 0.8769 - val_mse: 0.8769\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 0s 424us/step - loss: 5.1977 - mse: 5.1977 - val_loss: 1.0141 - val_mse: 1.0141\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 0s 410us/step - loss: 4.0290 - mse: 4.0290 - val_loss: 0.7505 - val_mse: 0.7505\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 0s 424us/step - loss: 5.9988 - mse: 5.9988 - val_loss: 0.7063 - val_mse: 0.7063\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 0s 420us/step - loss: 1.9661 - mse: 1.9661 - val_loss: 0.7277 - val_mse: 0.7277\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 0s 410us/step - loss: 1.9489 - mse: 1.9489 - val_loss: 10.2941 - val_mse: 10.2941\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 0s 480us/step - loss: 5.1534 - mse: 5.1534 - val_loss: 1.2871 - val_mse: 1.2871\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 0s 448us/step - loss: 1.3657 - mse: 1.3657 - val_loss: 13.0244 - val_mse: 13.0244\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 0s 426us/step - loss: 18.9839 - mse: 18.9839 - val_loss: 0.8752 - val_mse: 0.8752\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 0s 420us/step - loss: 0.8157 - mse: 0.8157 - val_loss: 0.8017 - val_mse: 0.8017\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.8514 - mse: 0.8514 - val_loss: 0.8834 - val_mse: 0.8834\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 0s 393us/step - loss: 1.1944 - mse: 1.1944 - val_loss: 0.7308 - val_mse: 0.7308\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 0s 416us/step - loss: 4.1283 - mse: 4.1283 - val_loss: 1.0150 - val_mse: 1.0150\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 0s 398us/step - loss: 1.0376 - mse: 1.0376 - val_loss: 0.6592 - val_mse: 0.6592\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 0s 420us/step - loss: 1.8151 - mse: 1.8151 - val_loss: 0.9293 - val_mse: 0.9293\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 0s 392us/step - loss: 2.5853 - mse: 2.5853 - val_loss: 0.6452 - val_mse: 0.6452\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 0s 394us/step - loss: 0.9986 - mse: 0.9986 - val_loss: 0.6357 - val_mse: 0.6357\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 0s 375us/step - loss: 1.0331 - mse: 1.0331 - val_loss: 0.6117 - val_mse: 0.6117\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 0s 366us/step - loss: 1.3375 - mse: 1.3375 - val_loss: 0.7245 - val_mse: 0.7245\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 0s 376us/step - loss: 1.8027 - mse: 1.8027 - val_loss: 12.1460 - val_mse: 12.1460\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 0s 365us/step - loss: 0.9199 - mse: 0.9199 - val_loss: 0.6419 - val_mse: 0.6419\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 0s 363us/step - loss: 0.7706 - mse: 0.7706 - val_loss: 0.6755 - val_mse: 0.6755\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 0s 365us/step - loss: 1.1060 - mse: 1.1060 - val_loss: 0.9079 - val_mse: 0.9079\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 0s 363us/step - loss: 2.1893 - mse: 2.1893 - val_loss: 0.7263 - val_mse: 0.7263\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 0s 377us/step - loss: 0.7549 - mse: 0.7549 - val_loss: 0.6497 - val_mse: 0.6497\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 0s 382us/step - loss: 0.8747 - mse: 0.8747 - val_loss: 0.6337 - val_mse: 0.6337\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 0s 372us/step - loss: 0.8416 - mse: 0.8416 - val_loss: 0.7974 - val_mse: 0.7974\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 0s 382us/step - loss: 0.7119 - mse: 0.7119 - val_loss: 0.7107 - val_mse: 0.7107\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 0s 369us/step - loss: 0.7262 - mse: 0.7262 - val_loss: 0.5901 - val_mse: 0.5901\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 0s 358us/step - loss: 0.8023 - mse: 0.8023 - val_loss: 0.9577 - val_mse: 0.9577\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 0s 362us/step - loss: 0.7075 - mse: 0.7075 - val_loss: 0.6504 - val_mse: 0.6504\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 0s 367us/step - loss: 0.8325 - mse: 0.8325 - val_loss: 0.7334 - val_mse: 0.7334\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 0s 370us/step - loss: 0.7275 - mse: 0.7275 - val_loss: 0.6164 - val_mse: 0.6164\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 0s 371us/step - loss: 0.6170 - mse: 0.6170 - val_loss: 0.6406 - val_mse: 0.6406\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 0s 384us/step - loss: 0.7679 - mse: 0.7679 - val_loss: 0.5971 - val_mse: 0.5971\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.6343 - mse: 0.6343 - val_loss: 0.5564 - val_mse: 0.5564\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 1.0647 - mse: 1.0647 - val_loss: 0.7667 - val_mse: 0.7667\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 0s 376us/step - loss: 0.6582 - mse: 0.6582 - val_loss: 0.8477 - val_mse: 0.8477\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 0s 382us/step - loss: 0.5793 - mse: 0.5793 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.6481 - mse: 0.6481 - val_loss: 0.7632 - val_mse: 0.7632\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 0s 503us/step - loss: 0.6084 - mse: 0.6084 - val_loss: 0.8073 - val_mse: 0.8073\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 0s 366us/step - loss: 0.5396 - mse: 0.5396 - val_loss: 0.6359 - val_mse: 0.6359\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 0s 379us/step - loss: 0.5570 - mse: 0.5570 - val_loss: 0.5535 - val_mse: 0.5535\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 0s 371us/step - loss: 0.5612 - mse: 0.5612 - val_loss: 0.5179 - val_mse: 0.5179\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.5312 - mse: 0.5312 - val_loss: 0.5642 - val_mse: 0.5642\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.5397 - mse: 0.5397 - val_loss: 0.4978 - val_mse: 0.4978\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 0s 366us/step - loss: 0.5087 - mse: 0.5087 - val_loss: 0.6666 - val_mse: 0.6666\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 0s 368us/step - loss: 0.5247 - mse: 0.5247 - val_loss: 0.6423 - val_mse: 0.6423\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 0s 380us/step - loss: 0.5055 - mse: 0.5055 - val_loss: 0.4761 - val_mse: 0.4761\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 0s 385us/step - loss: 0.5196 - mse: 0.5196 - val_loss: 0.6752 - val_mse: 0.6752\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.5282 - mse: 0.5282 - val_loss: 0.9644 - val_mse: 0.9644\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 0s 363us/step - loss: 0.5083 - mse: 0.5083 - val_loss: 0.6837 - val_mse: 0.6837\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 0s 367us/step - loss: 0.5361 - mse: 0.5361 - val_loss: 0.6579 - val_mse: 0.6579\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.5262 - mse: 0.5262 - val_loss: 0.5129 - val_mse: 0.5129\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 0s 391us/step - loss: 0.5160 - mse: 0.5160 - val_loss: 0.5002 - val_mse: 0.5002\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 0s 397us/step - loss: 0.5123 - mse: 0.5123 - val_loss: 0.6807 - val_mse: 0.6807\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.5108 - mse: 0.5108 - val_loss: 0.8273 - val_mse: 0.8273\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 0s 413us/step - loss: 0.5125 - mse: 0.5125 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 0s 431us/step - loss: 0.5018 - mse: 0.5018 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 0s 420us/step - loss: 0.5058 - mse: 0.5058 - val_loss: 0.5100 - val_mse: 0.5100\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 0s 415us/step - loss: 0.5066 - mse: 0.5066 - val_loss: 0.5578 - val_mse: 0.5578\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 0s 396us/step - loss: 0.4967 - mse: 0.4967 - val_loss: 0.5151 - val_mse: 0.5151\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 0s 372us/step - loss: 0.4838 - mse: 0.4838 - val_loss: 0.6356 - val_mse: 0.6356\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 0s 362us/step - loss: 0.4942 - mse: 0.4942 - val_loss: 0.4966 - val_mse: 0.4966\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 0s 368us/step - loss: 0.4927 - mse: 0.4927 - val_loss: 0.5351 - val_mse: 0.5351\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 0s 404us/step - loss: 0.5088 - mse: 0.5088 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 0s 428us/step - loss: 0.5664 - mse: 0.5664 - val_loss: 0.7069 - val_mse: 0.7069\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 0s 516us/step - loss: 0.4895 - mse: 0.4895 - val_loss: 0.9480 - val_mse: 0.9480\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 0s 430us/step - loss: 0.4814 - mse: 0.4814 - val_loss: 0.4953 - val_mse: 0.4953\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 0s 429us/step - loss: 0.4888 - mse: 0.4888 - val_loss: 0.5220 - val_mse: 0.5220\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 0s 418us/step - loss: 0.4809 - mse: 0.4809 - val_loss: 0.4868 - val_mse: 0.4868\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.4780 - mse: 0.4780 - val_loss: 0.5166 - val_mse: 0.5166\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.4817 - mse: 0.4817 - val_loss: 0.5141 - val_mse: 0.5141\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 0s 378us/step - loss: 0.4697 - mse: 0.4697 - val_loss: 0.6088 - val_mse: 0.6088\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 0s 397us/step - loss: 0.4713 - mse: 0.4713 - val_loss: 0.6419 - val_mse: 0.6419\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 0s 378us/step - loss: 0.4899 - mse: 0.4899 - val_loss: 0.5691 - val_mse: 0.5691\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 0s 437us/step - loss: 0.4675 - mse: 0.4675 - val_loss: 0.6295 - val_mse: 0.6295\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 0s 456us/step - loss: 0.5156 - mse: 0.5156 - val_loss: 0.6413 - val_mse: 0.6413\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 0s 424us/step - loss: 0.4717 - mse: 0.4717 - val_loss: 0.6232 - val_mse: 0.6232\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 0s 409us/step - loss: 0.4854 - mse: 0.4854 - val_loss: 0.7395 - val_mse: 0.7395\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 0s 399us/step - loss: 0.4712 - mse: 0.4712 - val_loss: 0.5488 - val_mse: 0.5488\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 0s 426us/step - loss: 0.4686 - mse: 0.4686 - val_loss: 0.4912 - val_mse: 0.4912\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 0s 371us/step - loss: 0.4727 - mse: 0.4727 - val_loss: 0.5126 - val_mse: 0.5126\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 0s 372us/step - loss: 0.4616 - mse: 0.4616 - val_loss: 0.5797 - val_mse: 0.5797\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 0s 365us/step - loss: 0.4669 - mse: 0.4669 - val_loss: 0.7116 - val_mse: 0.7116\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 0s 365us/step - loss: 0.4593 - mse: 0.4593 - val_loss: 0.9300 - val_mse: 0.9300\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 0s 377us/step - loss: 0.4676 - mse: 0.4676 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 0s 370us/step - loss: 0.4723 - mse: 0.4723 - val_loss: 0.5157 - val_mse: 0.5157\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 0s 373us/step - loss: 0.4707 - mse: 0.4707 - val_loss: 0.5373 - val_mse: 0.5373\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 0s 439us/step - loss: 0.4672 - mse: 0.4672 - val_loss: 0.5120 - val_mse: 0.5120\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.4862 - mse: 0.4862 - val_loss: 0.5091 - val_mse: 0.5091\n",
      "最终MSE: 0.4862\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
