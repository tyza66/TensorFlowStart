{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T07:26:18.966840Z",
     "start_time": "2026-01-14T07:19:07.679904Z"
    }
   },
   "source": [
    "# 生成手写数字的实例\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 使用手写字体或单品样本做训练 这里注意的是 我们只需要训练数据，不需要答案和测试数据集。\n",
    "(train_images, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "# 因为卷积层的需求，增加色深维度\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28,\n",
    "                                    1).astype('float32')\n",
    "# 规范化为-1 - +1\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "BUFFER_SIZE = 60000  # 以供60000个样本\n",
    "BATCH_SIZE = 256  # 256张为一组\n",
    "# 创建数据集\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# 生成器网络\n",
    "def make_generator_model():  # 根据长度为100的随机数组，生成一张28，28，1的矩阵\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(100,)))\n",
    "    # 全联接层，输入纬度为[[100],[n]], 输出为7*7*256 = 12544的节点 use_bias=False不使用偏差\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False))\n",
    "    # BatchNormalization层：该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1\n",
    "    # 该层作用：（1）加速收敛（2）控制过拟合，可以少用或不用Dropout和正则（3）降低网络对初始化权重不敏感（4）允许使用较大的学习率\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # ReLU是将所有的负值都设为零，相反，Leaky ReLU是给所有负值赋予一个非零斜率（负数）\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # 将平铺的节点转为7*7*256的shape\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    # 通俗的讲这个解卷积，也就做反卷积，也叫做转置卷积（最贴切），我们就叫做反卷积吧，它的目的就是卷积的反向操作\n",
    "    # 个人理解，正常的卷积是提取卷积核特征，反卷积就是用卷积核反向修改图像，风格迁移应该也是这么回事，那么问题来了在这个gan中，卷积特征从哪来？\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1),\n",
    "                                     padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # 64, (5, 5), strides=(2, 2), 希望得到64个特征核，步长2，2\n",
    "    # model.output_shape == (None, 14, 14, 64) 输出的节点数64就是上面的特征核，由于padding='same'，所以卷积后无变化，\n",
    "    # 14，14 是因为步长 2，2 所以7*2\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     use_bias=False, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# 判别器网络\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(28, 28, 1)))\n",
    "    # 将 28.28.1的图像卷积 输出64个节点\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 接着卷积出128个节点\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    # 激活函数 为非0的斜率\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 平铺 并输出一个数字\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "# 交叉熵损失函数\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# 辨别模型损失函数\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    # 样本图希望结果趋近1\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    # 自己生成的图希望结果趋近0\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    # 总损失\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# 生成模型的损失函数\n",
    "def generator_loss(fake_output):\n",
    "    # 生成模型期望最终的结果越来越接近1，也就是真实样本\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# 优化器\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "EPOCHS = 100  # 训练轮数\n",
    "noise_dim = 100  # 噪声向量的维度\n",
    "num_examples_to_generate = 16  # 生成图片数量\n",
    "# 初始化16个种子向量，用于生成4x4的图片 seed shape: 16, 100\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "def train_step(images):  # 更新 模型权重数据的核心方法\n",
    "    # 随机生成一个批次的种子向量 BATCH_SIZE = 256 noise_dim = 100 ，256个长度为100的噪音响亮\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])  # noise shape:[256],[100]\n",
    "    # 查看每一次epoch参数更新 这个GradientTape 是每次梯度更新都会调用的，这个取代了model.fit的训练计算\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # 生成一个批次的图片\n",
    "        generated_images = generator(noise, training=True)\n",
    "        # 辨别一个批次的真实样本\n",
    "        real_output = discriminator(images, training=True)\n",
    "        # 辨别一个批次的生成图片\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        # 计算两个损失值\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    # 根据损失值调整模型的权重参量\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # 计算出的参量应用到模型 梯度修剪，用于改变值， 梯度修剪主要避免训练梯度爆炸和消失问题\n",
    "    # zIP是个格式转换函数 例如：a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]； zip(*a) =[(1, 4, 7), (2, 5, 8), (3, 6, 9)]\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,\n",
    "                                                discriminator.trainable_variables))\n",
    "\n",
    "# 训练\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs + 1):\n",
    "        start = time.time()\n",
    "        # 训练\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "    # 保存图片\n",
    "    # 每个训练批次生成一张图片作为阶段成功\n",
    "    print(\"=======================================\")\n",
    "    generate_and_save_images(generator, epoch + 1, seed)\n",
    "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "# 生成图片\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # 设置为非训练状态，生成一组图片\n",
    "    predictions = model(test_input, training=False)\n",
    "    # 4格x4格拼接\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    # 保存为png\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 以训练模式运行，进入训练状态\n",
    "train(train_dataset, EPOCHS)  # 有点消耗电脑 我先不训练了 总之理论就是有一个生成器和一个判别器，他俩对抗"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/55/h39_3yj936z96fz3jb760jxm0000gn/T/ipykernel_57290/2030122454.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m \u001B[0;31m#生成手写数字的实例\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mabsolute_import\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdivision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprint_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0municode_literals\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/55/h39_3yj936z96fz3jb760jxm0000gn/T/ipykernel_57290/2030122454.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(dataset, epochs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0;31m# 训练\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mimage_batch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m             \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m     \u001B[0;31m# 保存图片\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m     \u001B[0;31m# 每个训练批次生成一张图片作为阶段成功\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"=======================================\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/55/h39_3yj936z96fz3jb760jxm0000gn/T/ipykernel_57290/2030122454.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(images)\u001B[0m\n\u001B[1;32m    102\u001B[0m         \u001B[0;31m# 计算两个损失值\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[0mgen_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerator_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfake_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0mdisc_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdiscriminator_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreal_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfake_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;31m# 根据损失值调整模型的权重参量\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m     \u001B[0mgradients_of_generator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen_tape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgen_loss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m     \u001B[0mgradients_of_discriminator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdisc_tape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdisc_loss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdiscriminator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;31m# 计算出的参量应用到模型 梯度修剪，用于改变值， 梯度修剪主要避免训练梯度爆炸和消失问题\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/项目/TensorFlowStart/.venv/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1059\u001B[0m               output_gradients))\n\u001B[1;32m   1060\u001B[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001B[1;32m   1061\u001B[0m                           for x in output_gradients]\n\u001B[1;32m   1062\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1063\u001B[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001B[0m\u001B[1;32m   1064\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1065\u001B[0m         \u001B[0mflat_targets\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m         \u001B[0mflat_sources\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/项目/TensorFlowStart/.venv/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     63\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m     raise ValueError(\n\u001B[1;32m     65\u001B[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001B[0m\u001B[1;32m     68\u001B[0m       \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m       \u001B[0msources\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/项目/TensorFlowStart/.venv/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    142\u001B[0m     \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"gradient_tape/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/项目/TensorFlowStart/.venv/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(op, grad)\u001B[0m\n\u001B[1;32m    589\u001B[0m           \u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m           \u001B[0mexplicit_paddings\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexplicit_paddings\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    591\u001B[0m           \u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m           data_format=data_format),\n\u001B[0;32m--> 593\u001B[0;31m       gen_nn_ops.conv2d_backprop_filter(\n\u001B[0m\u001B[1;32m    594\u001B[0m           \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m           \u001B[0mshape_1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    596\u001B[0m           \u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/项目/TensorFlowStart/.venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   1261\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1262\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1263\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1264\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1265\u001B[0;31m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1266\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1267\u001B[0m       return conv2d_backprop_filter_eager_fallback(\n\u001B[1;32m   1268\u001B[0m           \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilter_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout_backprop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstrides\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstrides\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
