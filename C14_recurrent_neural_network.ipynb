{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T06:00:44.916684Z",
     "start_time": "2026-01-14T06:00:09.148352Z"
    }
   },
   "source": [
    "# IMDB数据集展示SimpleRNN的使用\n",
    "import tensorflow as tf\n",
    "\n",
    "# 这是一个二分类情感分析数据集\n",
    "from keras.datasets import imdb\n",
    "from keras import Input, layers\n",
    "\n",
    "# 加载 IMDB 数据集\n",
    "max_features = 10000 # 使用词汇表中前 10000 个常见单词\n",
    "maxlen = 100 # 每条评论的最大长度\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train) # 标签 0-负面 1-正面\n",
    "\n",
    "# 数据预处理：填充序列，使其长度相同\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(x_train.shape)\n",
    "print(x_train[0]) # 填充后的序列\n",
    "\n",
    "# 构建RNN模型\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(maxlen,)), # 输入层，输入形状为(maxlen,)\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128), # 嵌入层 价格单词索引映射到128维向量\n",
    "    layers.SimpleRNN(128), # SimpleRNN层，128个单元\n",
    "    layers.Dense(1, activation='sigmoid') # 输出层，二分类使用sig\n",
    "])\n",
    "\n",
    "# 模型编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型训练\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "# 模型评估\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"测试集上的准确率: {test_acc:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "[1 0 0 ... 0 1 0]\n",
      "(25000, 100)\n",
      "[1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n",
      "    2    8    4  107  117 5952   15  256    4    2    7 3766    5  723\n",
      "   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n",
      "  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n",
      " 7486   18    4  226   22   21  134  476   26  480    5  144   30 5535\n",
      "   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n",
      "   88   12   16  283    5   16 4472  113  103   32   15   16 5345   19\n",
      "  178   32]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1313025 (5.01 MB)\n",
      "Trainable params: 1313025 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.5632 - accuracy: 0.6912 - val_loss: 0.4165 - val_accuracy: 0.8159\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.3927 - accuracy: 0.8320 - val_loss: 0.4424 - val_accuracy: 0.8124\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.3922 - accuracy: 0.8329 - val_loss: 0.4437 - val_accuracy: 0.8113\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.3653 - accuracy: 0.8420 - val_loss: 0.5439 - val_accuracy: 0.7223\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.4468 - accuracy: 0.8021 - val_loss: 0.5094 - val_accuracy: 0.7774\n",
      "782/782 - 2s - loss: 0.5094 - accuracy: 0.7774 - 2s/epoch - 2ms/step\n",
      "测试集上的准确率: 0.7774\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T06:22:28.300691Z",
     "start_time": "2026-01-14T06:21:05.651474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IMDB数据集展示LSTM的使用\n",
    "\n",
    "# 加载 IMDB 数据集\n",
    "max_features = 10000 # 使用词汇表中前 10000 个常见单词\n",
    "maxlen = 100 # 每条评论的最大长度\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train) # 标签 0-负面 1-正面\n",
    "\n",
    "# 数据预处理：填充序列，使其长度相同\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(x_train.shape)\n",
    "print(x_train[0]) # 填充后的序列\n",
    "\n",
    "# 构建RNN模型\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(maxlen,)), # 输入层，输入形状为(maxlen,)\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128), # 嵌入层 价格单词索引映射到128维向量\n",
    "    layers.LSTM(units=64,dropout=0.2,recurrent_dropout=0.2), # LSTM层，64个单元 recurrent_dropout是对循环连接的dropout\n",
    "    layers.Dense(1, activation='sigmoid') # 输出层，二分类使用sig\n",
    "])\n",
    "\n",
    "# 模型编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型训练\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "# 模型评估\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"测试集上的准确率: {test_acc:.4f}\")"
   ],
   "id": "ff161b59f6785e8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "[1 0 0 ... 0 1 0]\n",
      "(25000, 100)\n",
      "[1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n",
      "    2    8    4  107  117 5952   15  256    4    2    7 3766    5  723\n",
      "   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n",
      "  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n",
      " 7486   18    4  226   22   21  134  476   26  480    5  144   30 5535\n",
      "   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n",
      "   88   12   16  283    5   16 4472  113  103   32   15   16 5345   19\n",
      "  178   32]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1329473 (5.07 MB)\n",
      "Trainable params: 1329473 (5.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "391/391 [==============================] - 16s 39ms/step - loss: 0.4212 - accuracy: 0.7975 - val_loss: 0.3407 - val_accuracy: 0.8524\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.2603 - accuracy: 0.8950 - val_loss: 0.3465 - val_accuracy: 0.8485\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.1878 - accuracy: 0.9281 - val_loss: 0.4200 - val_accuracy: 0.8408\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.1430 - accuracy: 0.9453 - val_loss: 0.5309 - val_accuracy: 0.8362\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.1136 - accuracy: 0.9584 - val_loss: 0.6406 - val_accuracy: 0.8120\n",
      "782/782 - 3s - loss: 0.6406 - accuracy: 0.8120 - 3s/epoch - 4ms/step\n",
      "测试集上的准确率: 0.8120\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T06:37:29.049706Z",
     "start_time": "2026-01-14T06:36:22.589671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IMDB数据集展示GRU的使用\n",
    "\n",
    "# 加载 IMDB 数据集\n",
    "max_features = 10000 # 使用词汇表中前 10000 个常见单词\n",
    "maxlen = 100 # 每条评论的最大长度\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train) # 标签 0-负面 1-正面\n",
    "\n",
    "# 数据预处理：填充序列，使其长度相同\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(x_train.shape)\n",
    "print(x_train[0]) # 填充后的序列\n",
    "\n",
    "# 构建RNN模型\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(maxlen,)), # 输入层，输入形状为(maxlen,)\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128), # 嵌入层 价格单词索引映射到128维向量\n",
    "    layers.GRU(units=64,dropout=0.2,recurrent_dropout=0.2), # GRU层，64个单元 recurrent_dropout是对循环连接的dropout\n",
    "    layers.Dense(1, activation='sigmoid') # 输出层，二分类使用sig\n",
    "])\n",
    "\n",
    "# 模型编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型训练\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "# 模型评估\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"测试集上的准确率: {test_acc:.4f}\") # 这回效率高一点"
   ],
   "id": "7de60706ac37e2fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "[1 0 0 ... 0 1 0]\n",
      "(25000, 100)\n",
      "[1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n",
      "    2    8    4  107  117 5952   15  256    4    2    7 3766    5  723\n",
      "   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n",
      "  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n",
      " 7486   18    4  226   22   21  134  476   26  480    5  144   30 5535\n",
      "   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n",
      "   88   12   16  283    5   16 4472  113  103   32   15   16 5345   19\n",
      "  178   32]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1317313 (5.03 MB)\n",
      "Trainable params: 1317313 (5.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.4488 - accuracy: 0.7769 - val_loss: 0.3535 - val_accuracy: 0.8461\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.2722 - accuracy: 0.8899 - val_loss: 0.3505 - val_accuracy: 0.8507\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.2133 - accuracy: 0.9175 - val_loss: 0.3587 - val_accuracy: 0.8504\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1518 - accuracy: 0.9450 - val_loss: 0.4161 - val_accuracy: 0.8452\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1074 - accuracy: 0.9625 - val_loss: 0.4734 - val_accuracy: 0.8370\n",
      "782/782 - 2s - loss: 0.4734 - accuracy: 0.8370 - 2s/epoch - 3ms/step\n",
      "测试集上的准确率: 0.8370\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
